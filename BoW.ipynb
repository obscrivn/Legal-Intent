{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Word2VecUtility import Word2VecUtility\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1087, 3)\n",
      "                                                 txt general_label  id\n",
      "0  ATTORNEYS FOR APPELLANT\\nRobert D. MacGill\\nMi...         Civil   1\n",
      "1  ATTORNEYS FOR APPELLANT\\nJohn D. LaDue\\nErin L...      Criminal   2\n",
      "2  ATTORNEYS FOR APPELLANTS\\nBryan L. Ciyou\\nLori...    Government   3\n",
      "3  ATTORNEYS FOR APPELLANTS\\nRobert E. Lehman\\nIn...      Criminal   4\n",
      "4  ATTORNEYS FOR APPELLANTS\\n\\nATTORNEYS FOR APPE...      Criminal   5\n",
      "                                                   txt   general_label   id\n",
      "245  ATTORNEYS FOR APPELLANTS\\nCENTER TOWNSHIP TRUS...           Civil  246\n",
      "246  ATTORNEY FOR APPELLANT\\n\\nATTORNEYS FOR APPELL...           Civil  247\n",
      "247  ATTORNEYS FOR APPELLANT\\n\\nATTORNEYS FOR APPEL...  Constitutional  248\n",
      "248  ATTORNEY FOR APPELLANT\\nAmy O. Carson\\nIndiana...        Criminal  249\n",
      "249  ATTORNEY FOR APPELLANT\\n\\nATTORNEYS FOR APPELL...          Family  250\n",
      "250  ATTORNEY FOR APPELLANT\\nJim Brugh\\nLogansport,...             NaN  251\n",
      "251  ATTORNEY FOR APPELLANTS\\nKatherine A. Brown-He...             NaN  252\n",
      "252  ATTORNEY FOR APPELLANT\\n\\nATTORNEYS FOR APPELL...             NaN  253\n",
      "253  ATTORNEYS FOR APPELLANT\\n\\nATTORNEYS FOR APPEL...             NaN  254\n",
      "254  ATTORNEY FOR APPELLANT\\n\\nATTORNEYS FOR APPELL...             NaN  255\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"IN-gov-txts.tsv\", sep = '\\t', encoding = 'utf-8',\\\n",
    "                 quoting = csv.QUOTE_MINIMAL)\n",
    "df['id'] = range(1, df.shape[0]+1)\n",
    "print df.shape\n",
    "print df.iloc[:5, :]\n",
    "print df.iloc[245:255, :]\n",
    "# df.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the case txt files...\n",
      "\n",
      "finished!\n"
     ]
    }
   ],
   "source": [
    "# for supervised learning\n",
    "df = df[pd.notnull(df['general_label'])]\n",
    "np.random.seed(520)\n",
    "mask = np.random.rand(len(df)) < 0.8\n",
    "train = df[mask]\n",
    "test = df[~mask]\n",
    "\n",
    "train_clean = []\n",
    "print \"Cleaning and parsing the case txt files...\\n\"\n",
    "for txt in train[\"txt\"]:\n",
    "    train_clean.append(\" \".join(Word2VecUtility.review_to_wordlist(txt, True)))\n",
    "\n",
    "test_clean = []\n",
    "for txt in test[\"txt\"]:\n",
    "    test_clean.append(\" \".join(Word2VecUtility.review_to_wordlist(txt, True)))\n",
    "print \"finished!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n",
      "Fitting a svm to labeled training data...\n",
      "accuracy on train: 100/100\n",
      "accuracy on test: 0/100\n",
      "Fitting a random forest to labeled training data...\n",
      "accuracy on train: 100/100\n",
      "accuracy on test: 0/100\n"
     ]
    }
   ],
   "source": [
    "# for supervised learning\n",
    "\n",
    "# ****** Create a bag of words from the training set\n",
    "#\n",
    "print \"Creating the bag of words...\\n\"\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                         tokenizer = None,    \\\n",
    "                         preprocessor = None, \\\n",
    "                         stop_words = None,   \\\n",
    "                         max_features = 50)\n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of\n",
    "# strings.\n",
    "train_data_features = vectorizer.fit_transform(train_clean)\n",
    "test_data_features = vectorizer.transform(test_clean)\n",
    "# Numpy arrays are easy to work with, so convert the result to an\n",
    "# array\n",
    "train_data_features = train_data_features.toarray()\n",
    "test_data_features = test_data_features.toarray()\n",
    "# ******* Train a random forest using the bag of words\n",
    "#\n",
    "classifiers = { 'random forest' : RandomForestClassifier(n_estimators = 20),\n",
    "                'svm' : svm.SVC(C = 5.0)}\n",
    "for name, classifier in classifiers.items():\n",
    "    print \"Fitting a %s to labeled training data...\" %(name)\n",
    "    classifier.fit( train_data_features, train['general_label'])\n",
    "    train_pred = classifier.predict( train_data_features )\n",
    "    test_pred = classifier.predict( test_data_features)\n",
    "    # accuracy\n",
    "    print(\"accuracy on train: %d/100\" %(sum(train_pred == train['general_label'])/len(train) *100))\n",
    "    print(\"accuracy on test: %d/100\" %(sum(test_pred == test['general_label'])/len(test) *100))\n",
    "# Write the train predict results\n",
    "# output = pd.DataFrame( data={\"id\":test[\"id\"], \"predict_label\":test_pred} )\n",
    "# output.to_csv( \"Word2Vec_AverageVectors_predict.csv\", index=False, quoting=3 )\n",
    "# print \"Wrote Word2Vec_AverageVectors_predict.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1087, 3)\n",
      "Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
      "            ...\n",
      "            1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086],\n",
      "           dtype='int64', length=1087)\n",
      "1087\n",
      "0     1\n",
      "1     2\n",
      "2     3\n",
      "3     4\n",
      "4     5\n",
      "5     6\n",
      "6     7\n",
      "7     8\n",
      "8     9\n",
      "9    10\n",
      "Name: id, dtype: int64\n",
      "                                                   txt   general_label   id\n",
      "245  ATTORNEYS FOR APPELLANTS\\nCENTER TOWNSHIP TRUS...           Civil  246\n",
      "246  ATTORNEY FOR APPELLANT\\n\\nATTORNEYS FOR APPELL...           Civil  247\n",
      "247  ATTORNEYS FOR APPELLANT\\n\\nATTORNEYS FOR APPEL...  Constitutional  248\n",
      "248  ATTORNEY FOR APPELLANT\\nAmy O. Carson\\nIndiana...        Criminal  249\n",
      "249  ATTORNEY FOR APPELLANT\\n\\nATTORNEYS FOR APPELL...          Family  250\n",
      "250  ATTORNEY FOR APPELLANT\\nJim Brugh\\nLogansport,...              -1  251\n",
      "251  ATTORNEY FOR APPELLANTS\\nKatherine A. Brown-He...              -1  252\n",
      "252  ATTORNEY FOR APPELLANT\\n\\nATTORNEYS FOR APPELL...              -1  253\n",
      "253  ATTORNEYS FOR APPELLANT\\n\\nATTORNEYS FOR APPEL...              -1  254\n",
      "254  ATTORNEY FOR APPELLANT\\n\\nATTORNEYS FOR APPELL...              -1  255\n",
      "there are 16 unique labels in total\n"
     ]
    }
   ],
   "source": [
    "# for semi-supervised learning\n",
    "df.ix[pd.isnull(df['general_label']),'general_label'] = -1\n",
    "print df.shape\n",
    "print df.index\n",
    "print len(df)\n",
    "print df['id'][:10]\n",
    "print df.iloc[245:255, :]\n",
    "print \"there are %d unique labels in total\" % len(set(df['general_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the case txt files...\n",
      "\n",
      "Creating the bag of words...\n",
      "\n",
      "(1087, 300)\n",
      "accuracy: 1/250\n"
     ]
    }
   ],
   "source": [
    "# for semi-supervised learning\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "clean_df = []\n",
    "print \"Cleaning and parsing the case txt files...\\n\"\n",
    "for txt in df[\"txt\"]:\n",
    "    clean_df.append(\" \".join(Word2VecUtility.review_to_wordlist(txt, True)))\n",
    "    \n",
    "print \"Creating the bag of words...\\n\"\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                         tokenizer = None,    \\\n",
    "                         preprocessor = None, \\\n",
    "                         stop_words = None,   \\\n",
    "                         max_features = 300)\n",
    "X = vectorizer.fit_transform(clean_df).toarray()\n",
    "print X.shape\n",
    "y = df['general_label']\n",
    "label_prop_model = LabelPropagation(kernel='rbf', gamma=20, \\\n",
    "                                    n_neighbors=3, alpha=1, max_iter=30, tol=0.001)\n",
    "label_prop_model.fit(X, y)\n",
    "y_pred = label_prop_model.predict(X)\n",
    "labeled_index = np.where(df['general_label'] != -1)\n",
    "print 'accuracy: %d/%d' %(np.sum(y_pred[labeled_index] == y.ix[labeled_index]),\\\n",
    "                          len(labeled_index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
