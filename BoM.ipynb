{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1087, 3)\n",
      "                                                 txt general_label  id\n",
      "0  ATTORNEYS FOR APPELLANT\\nRobert D. MacGill\\nMi...         Civil   1\n",
      "1  ATTORNEYS FOR APPELLANT\\nJohn D. LaDue\\nErin L...      Criminal   2\n",
      "2  ATTORNEYS FOR APPELLANTS\\nBryan L. Ciyou\\nLori...    Government   3\n",
      "3  ATTORNEYS FOR APPELLANTS\\nRobert E. Lehman\\nIn...      Criminal   4\n",
      "4  ATTORNEYS FOR APPELLANTS\\n\\nATTORNEYS FOR APPE...      Criminal   5\n",
      "                                                   txt general_label   id\n",
      "145  ATTORNEY FOR APPELLANT\\n\\nATTORNEYS FOR APPELL...         Civil  146\n",
      "146  ATTORNEY FOR APPELLANT\\nDeborah Markisohn\\nInd...      Criminal  147\n",
      "147  ATTORNEY FOR APPELLANT\\nRobert T. Sanders III\\...      Criminal  148\n",
      "148  ATTORNEY FOR APPELLANT\\nKimberly A. Jackson\\nI...      Criminal  149\n",
      "149  ATTORNEYS FOR APPELLANTS\\n\\nATTORNEYS FOR AMIC...      Criminal  150\n",
      "150  ATTORNEYS FOR APPELLANT\\n\\nATTORNEYS FOR APPEL...      Criminal  151\n",
      "151  ATTORNEYS FOR APPELLANT\\n\\nATTORNEYS FOR APPEL...         Civil  152\n",
      "152  ATTORNEYS FOR APPELLANT\\nRobert D. King, Jr.\\n...      Criminal  153\n",
      "153  ATTORNEY FOR APPELLANT\\n\\nATTORNEYS FOR APPELL...         Civil  154\n",
      "154  ATTORNEY FOR APPELLANT\\n\\nATTORNEYS FOR APPELL...      Criminal  155\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"IN-gov-txts.tsv\", sep = '\\t', encoding = 'utf-8',\\\n",
    "                 quoting = csv.QUOTE_MINIMAL)\n",
    "df['id'] = range(1, df.shape[0]+1)\n",
    "print df.shape\n",
    "print df.iloc[:5, :]\n",
    "print df.iloc[145:155, :]\n",
    "# df.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1087, 3)\n",
      "Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
      "            ...\n",
      "            1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086],\n",
      "           dtype='int64', length=1087)\n",
      "1087\n",
      "0     1\n",
      "1     2\n",
      "2     3\n",
      "3     4\n",
      "4     5\n",
      "5     6\n",
      "6     7\n",
      "7     8\n",
      "8     9\n",
      "9    10\n",
      "Name: id, dtype: int64\n",
      "                                                   txt   general_label   id\n",
      "245  ATTORNEYS FOR APPELLANTS\\nCENTER TOWNSHIP TRUS...           Civil  246\n",
      "246  ATTORNEY FOR APPELLANT\\n\\nATTORNEYS FOR APPELL...           Civil  247\n",
      "247  ATTORNEYS FOR APPELLANT\\n\\nATTORNEYS FOR APPEL...  Constitutional  248\n",
      "248  ATTORNEY FOR APPELLANT\\nAmy O. Carson\\nIndiana...        Criminal  249\n",
      "249  ATTORNEY FOR APPELLANT\\n\\nATTORNEYS FOR APPELL...          Family  250\n",
      "250  ATTORNEY FOR APPELLANT\\nJim Brugh\\nLogansport,...              -1  251\n",
      "251  ATTORNEY FOR APPELLANTS\\nKatherine A. Brown-He...              -1  252\n",
      "252  ATTORNEY FOR APPELLANT\\n\\nATTORNEYS FOR APPELL...              -1  253\n",
      "253  ATTORNEYS FOR APPELLANT\\n\\nATTORNEYS FOR APPEL...              -1  254\n",
      "254  ATTORNEY FOR APPELLANT\\n\\nATTORNEYS FOR APPELL...              -1  255\n",
      "there are 16 unique labels in total\n"
     ]
    }
   ],
   "source": [
    "# df = df[pd.notnull(df['general_label'])]\n",
    "df.ix[pd.isnull(df['general_label']),'general_label'] = -1\n",
    "print df.shape\n",
    "print df.index\n",
    "print len(df)\n",
    "print df['id'][:10]\n",
    "print df.iloc[245:255, :]\n",
    "print \"there are %d unique labels in total\" % len(set(df['general_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn import svm\n",
    "from Word2VecUtility import Word2VecUtility\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeFeatureVec(words, model, num_features):\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    nwords = 0.\n",
    "    # Index2word is a list that contains the names of the words in\n",
    "    # the model's vocabulary. Convert it to a set, for speed\n",
    "    index2word_set = set(model.index2word)\n",
    "    #\n",
    "    # Loop over each word in the review and, if it is in the model's\n",
    "    # vocaublary, add its feature vector to the total\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    #\n",
    "    # Divide the result by the number of words to get the average\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec\n",
    "\n",
    "\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    counter = 0.\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    for review in reviews:\n",
    "        reviewFeatureVecs[counter] = makeFeatureVec(review, model, num_features)\n",
    "        counter = counter + 1.\n",
    "    return reviewFeatureVecs\n",
    "\n",
    "\n",
    "def getCleanReviews(reviews):\n",
    "    clean_reviews = []\n",
    "    for review in reviews['txt']:\n",
    "        clean_reviews.append( Word2VecUtility.review_to_wordlist\\\n",
    "                             ( review, remove_stopwords=True ))\n",
    "    return clean_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating average feature vecs for 127 train case txt\n",
      "Creating average feature vecs for 24 test case txt\n",
      "Fitting a svm to labeled training data...\n",
      "accuracy on train: 0/100\n",
      "accuracy on test: 0/100\n",
      "Fitting a random forest to labeled training data...\n",
      "accuracy on train: 100/100\n",
      "accuracy on test: 0/100\n"
     ]
    }
   ],
   "source": [
    "# only use those labeled data, supervised learning\n",
    "model = Word2Vec.load(\"300features_40minwords_10context\")\n",
    "num_features = 300\n",
    "np.random.seed(520)\n",
    "mask = np.random.rand(len(df)) < 0.8\n",
    "train = df[mask]\n",
    "test = df[~mask]\n",
    "\n",
    "print \"Creating average feature vecs for %d train case txt\" %len(train)\n",
    "trainDataVecs = getAvgFeatureVecs( getCleanReviews(train), model, num_features )\n",
    "print \"Creating average feature vecs for %d test case txt\" %len(test)\n",
    "testDataVecs = getAvgFeatureVecs( getCleanReviews(test), model, num_features )\n",
    "\n",
    "classifiers = { 'random forest' : RandomForestClassifier(n_estimators = 100),\n",
    "                'svm' : svm.SVC(C = 5.0)}\n",
    "for name, classifier in classifiers.items():\n",
    "    print \"Fitting a %s to labeled training data...\" %(name)\n",
    "    classifier.fit( trainDataVecs, train['general_label'])\n",
    "    train_pred = classifier.predict( trainDataVecs )\n",
    "    test_pred = classifier.predict( testDataVecs)\n",
    "    # accuracy\n",
    "    print(\"accuracy on train: %d/100\"%(sum(train_pred == train['general_label'])/len(train)*100))\n",
    "    print(\"accuracy on test: %d/100\"%(sum(test_pred == test['general_label'])/len(test) *100))\n",
    "    # Write the train predict results\n",
    "#     output = pd.DataFrame( data={\"id\":test[\"id\"], \"predict_label\":test_pred} )\n",
    "#     output.to_csv( \"Word2Vec_AverageVectors_predict.csv\", index=False, quoting=3 )\n",
    "#     print \"Wrote Word2Vec_AverageVectors_predict.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating average feature vecs for all(1087) case txt file...\n",
      "there are 16 unique labels in total\n",
      "accuracy: 106/250\n"
     ]
    }
   ],
   "source": [
    "# semisupervised learning\n",
    "model = Word2Vec.load(\"300features_40minwords_10context\")\n",
    "num_features = 300\n",
    "labeled_index = np.where(df['general_label'] != -1)\n",
    "print \"Creating average feature vecs for all(%d) case txt file...\" %len(df)\n",
    "print \"there are %d unique labels in total\" % len(set(df['general_label']))\n",
    "\n",
    "X = getAvgFeatureVecs( getCleanReviews(df), model, num_features )\n",
    "# replace nan value with 0.\n",
    "X[pd.isnull(X)] = 0\n",
    "y = df['general_label']\n",
    "label_prop_model = LabelPropagation(kernel='rbf', gamma=20, \\\n",
    "                                    n_neighbors=3, alpha=1, max_iter=30, tol=0.001)\n",
    "label_prop_model.fit(X, y)\n",
    "y_pred = label_prop_model.predict(X)\n",
    "print 'accuracy: %d/%d' %(np.sum(y_pred[labeled_index] == y.ix[labeled_index]),\\\n",
    "                          len(labeled_index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[pd.isnull(X)] = 0\n",
    "print np.isfinite(X).all()\n",
    "np.where(np.sum(np.isfinite(X), axis=1) != 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'tuple'>\n",
      "151\n"
     ]
    }
   ],
   "source": [
    "print type(labeled_index)\n",
    "print len(labeled_index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n"
     ]
    }
   ],
   "source": [
    "print sum(y == 'Criminal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
